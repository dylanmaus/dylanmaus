<!doctype html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Deep Learning Math | Dylan Maus</title>
<meta name="generator" content="Jekyll v4.0.1" />
<meta property="og:title" content="Deep Learning Math" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Introduction Consider the function \(z(x, y) = a \sin(x) + b \cos(y)\) and noisy data from sensors that measure \(z\) at many \((x, y)\) locations. Our goal is to fit the data with \(z(x, y)\) by finding the parameters \(a\) and \(b\). A nonlinear least squares approach such as the Gauss-Newton algorithm could be used to solve this nonlinear regression problem." />
<meta property="og:description" content="Introduction Consider the function \(z(x, y) = a \sin(x) + b \cos(y)\) and noisy data from sensors that measure \(z\) at many \((x, y)\) locations. Our goal is to fit the data with \(z(x, y)\) by finding the parameters \(a\) and \(b\). A nonlinear least squares approach such as the Gauss-Newton algorithm could be used to solve this nonlinear regression problem." />
<link rel="canonical" href="http://localhost:4000/projects/Deep-Learning-Math/Deep-Learning-Math.html" />
<meta property="og:url" content="http://localhost:4000/projects/Deep-Learning-Math/Deep-Learning-Math.html" />
<meta property="og:site_name" content="Dylan Maus" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2026-02-02T22:47:34-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Deep Learning Math" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2026-02-02T22:47:34-05:00","datePublished":"2026-02-02T22:47:34-05:00","description":"Introduction Consider the function \\(z(x, y) = a \\sin(x) + b \\cos(y)\\) and noisy data from sensors that measure \\(z\\) at many \\((x, y)\\) locations. Our goal is to fit the data with \\(z(x, y)\\) by finding the parameters \\(a\\) and \\(b\\). A nonlinear least squares approach such as the Gauss-Newton algorithm could be used to solve this nonlinear regression problem.","headline":"Deep Learning Math","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/projects/Deep-Learning-Math/Deep-Learning-Math.html"},"url":"http://localhost:4000/projects/Deep-Learning-Math/Deep-Learning-Math.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Dylan Maus" /></head>
<body><header class="site-header">
  <div class="wrapper"><a class="site-title" rel="author" href="/">
      Dylan Maus
    </a><nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
      <label for="nav-trigger">
        <span class="menu-icon">
          <svg viewBox="0 0 18 15" width="18px" height="15px">
            <path
              d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"
            />
          </svg>
        </span>
      </label>

      <div class="trigger"><a class="page-link" href="/contact/"
          >Contact</a
        ><a class="page-link" href="/gradschool/"
          >Grad School</a
        ></div>
    </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper"><article
  class="post h-entry"
  itemscope
  itemtype="http://schema.org/BlogPosting"
>
  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">
      Deep Learning Math
    </h1>
  </header>

  <div class="post-content e-content" itemprop="articleBody"><h2 id="introduction">Introduction</h2>
<p>Consider the function \(z(x, y) = a \sin(x) + b \cos(y)\) and noisy data from sensors that measure \(z\) at many \((x, y)\) locations. Our goal is to fit the data with \(z(x, y)\) by finding the parameters \(a\) and \(b\). A nonlinear least squares approach such as the Gauss-Newton algorithm could be used to solve this nonlinear regression problem.</p>

<p>In a real world scenario we may not even know the function \(z\) at all. It may be high dimensional and impossible to guess, so it must be approximated. To solve this more advanced problem, we propose a model such as an artificial neural network to approximate \(z\). Our goal here is similar, iteratively tune the model parameters to fit the data.</p>

<p>This post explains some of the math behind Deep Learning and why it may be preferred to other approaches.</p>

<h2 id="deep-learning">Deep learning</h2>
<h1 id="function-approximation">Function approximation</h1>
<p>To approximate the unknown function \(z\), consider a 2 layer fully connected neural network with 2 inputs, 3 nodes in the hidden layer, 1 output, and sigmoid activation function. The complete breakdown of the neural network \(f\) is shown below.</p>

\[\mathbf{x} = \begin{bmatrix}
x_0 \\
x_1
\end{bmatrix}\]

\[\mathbf{W}_0 = \begin{bmatrix}
\omega_0&amp; \omega_1 \\
\omega_2&amp; \omega_3 \\
\omega_4&amp; \omega_5
\end{bmatrix}\]

\[\mathbf{b}_0 = \begin{bmatrix}
b_0 \\
b_1 \\
b_2
\end{bmatrix}\]

\[\mathbf{W}_1 = \begin{bmatrix}
\omega_6 \\
\omega_7 \\
\omega_8
\end{bmatrix}\]

\[\mathbf{b}_1 = \begin{bmatrix}
b_3
\end{bmatrix}\]

\[f(\mathbf{x}) = \sigma(\sigma(\mathbf{W}_0\mathbf{x} + \mathbf{b}_0)\mathbf{W}_1 + \mathbf{b}_1)\]

\[f(\mathbf{x}) = \sigma\left(\sigma\left(
\begin{bmatrix}
\omega_0&amp; \omega_1 \\
\omega_2&amp; \omega_3 \\
\omega_4&amp; \omega_5
\end{bmatrix}
\begin{bmatrix}
x_0 \\
x_1
\end{bmatrix} +
\begin{bmatrix}
b_0 \\
b_1 \\
b_2
\end{bmatrix}
\right)
\begin{bmatrix}
\omega_6 \\
\omega_7 \\
\omega_8
\end{bmatrix} +
b_3
\right)\]

\[f(\mathbf{x}) = \sigma\left(\begin{bmatrix}
\sigma(\omega_0 x_0 + \omega_1 x_1 + b_0) \\
\sigma(\omega_2 x_0 + \omega_3 x_1 + b_1) \\
\sigma(\omega_4 x_0 + \omega_5 x_1 + b_2) \\
\end{bmatrix}^T
\begin{bmatrix}
\omega_6 \\
\omega_7 \\
\omega_8
\end{bmatrix}
+ b_3\right)\]

\[f(\mathbf{x}) = \sigma(
\sigma(\omega_0 x_0 + \omega_1 x_1 + b_0)\omega_6 +
\sigma(\omega_2 x_0 + \omega_3 x_1 + b_1)\omega_7 +
\sigma(\omega_4 x_0 + \omega_5 x_1 + b_2)\omega_8 +
b_3)\]

<h1 id="activation-function">Activation function</h1>

<p>Sigmoid</p>

\[\sigma = \frac{1}{1 + e^{-x}}\]

\[\frac{d\sigma}{dx} = \frac{e^{-x}}{(1 + e^{-x})^2}\]

<h1 id="loss">Loss</h1>
<p>We will use Mean squared error as our loss function.</p>

\[L = \frac{1}{N} \sum_{i=0}^N (f(\mathbf{x}_i) - y_i)^2\]

\[L = \frac{1}{N} \mathbf{1}^T \begin{bmatrix}
(f(\mathbf{x}_0) - y_0)^2 \\
\vdots \\
(f(\mathbf{x}_N) - y_N)^2
\end{bmatrix}\]

\[\mathbf{X} = \begin{bmatrix}
\mathbf{x}_0 \\
\vdots \\
\mathbf{x}_N
\end{bmatrix} = \begin{bmatrix}
x_0^0 &amp; x_1^0 \\
\vdots &amp; \vdots \\
x_0^N &amp; x_1^N
\end{bmatrix}\]

\[\mathbf{Y} = \begin{bmatrix}
y_0 \\
\vdots \\
y_N
\end{bmatrix}\]

\[L = \frac{1}{N} \mathbf{1}^T (f(\mathbf{X}) - \mathbf{Y})^2\]

<p>The objective of training the neural network is to minimize \(L\). During training, \(N\) is equal to the batch size.</p>

<h1 id="gradient-descent">Gradient descent</h1>

<p>The gradient is the derivative generalized to multiple dimensions that finds the direction of steepest ascent. This is applicable in maximization problems. However, minimization problems require finding the direction of steepest descent. So the negative gradient is computed.</p>

\[\nabla L = \begin{bmatrix}
\frac{\partial L}{\partial \mathbf{W}_0} \\
\frac{\partial L}{\partial \mathbf{W}_1} \\
\frac{\partial L}{\partial \mathbf{B}_0} \\
\frac{\partial L}{\partial \mathbf{B}_1} \\
\end{bmatrix}\]

\[\frac{\partial L}{\partial \mathbf{W}_0} =
\frac{2}{N} (\sigma(\sigma(\mathbf{W}_0\mathbf{X} + \mathbf{b}_0)\mathbf{W}_1 + \mathbf{b}_1) - \mathbf{Y})
d\sigma(\sigma(\mathbf{W}_0\mathbf{X} + \mathbf{b}_0)\mathbf{W}_1 + \mathbf{b}_1)
d\sigma(\mathbf{W}_0\mathbf{X} + \mathbf{b}_0)
\mathbf{W}_1 \mathbf{X}\]

\[\frac{\partial L}{\partial \mathbf{b}_0} =
\frac{2}{N} (\sigma(\sigma(\mathbf{W}_0\mathbf{X} + \mathbf{b}_0)\mathbf{W}_1 + \mathbf{b}_1) - \mathbf{Y})
d\sigma(\sigma(\mathbf{W}_0\mathbf{X} + \mathbf{b}_0)\mathbf{W}_1 + \mathbf{b}_1)
d\sigma(\mathbf{W}_0\mathbf{X} + \mathbf{b}_0)\]

\[\frac{\partial L}{\partial \mathbf{W}_1} =
\frac{2}{N} (\sigma(\sigma(\mathbf{W}_0\mathbf{X} + \mathbf{b}_0)\mathbf{W}_1 + \mathbf{b}_1) - \mathbf{Y})
d\sigma(\sigma(\mathbf{W}_0\mathbf{X} + \mathbf{b}_0)\mathbf{W}_1 + \mathbf{b}_1)
d\sigma(\mathbf{W}_0\mathbf{X} + \mathbf{b}_0)
\sigma(\mathbf{W}_0\mathbf{X} + \mathbf{b}_0)\]

\[\frac{\partial L}{\partial \mathbf{b}_1} =
\frac{2}{N} (\sigma(\sigma(\mathbf{W}_0\mathbf{X} + \mathbf{b}_0)\mathbf{W}_1 + \mathbf{b}_1) - \mathbf{Y})
d\sigma(\sigma(\mathbf{W}_0\mathbf{X} + \mathbf{b}_0) \mathbf{W}_1 + \mathbf{b}_1)\]

<p>Weight update</p>

\[\mathbf{W}_{n+1} = \mathbf{W}_n - \gamma \frac{\partial{W_n}}{\partial{L}}\]

<!-- \frac{d\sigma}{dW_0} -->

<!-- | ![](/assets/plot.svg) |
|:--:|
| $$ z(x, y) = a \sin(x) + b \cos(y) $$ |

<img src="/assets/plot.svg" alt="drawing" width="800"/> -->
<p>\(\LaTeX\)</p>
</div>

  <a class="u-url" href="/projects/Deep-Learning-Math/Deep-Learning-Math.html" hidden></a>
</article>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"
></script>
</div>
    </main><footer class="site-footer">
  <div class="wrapper">
    <!--<h2 class="footer-heading">Dylan Maus</h2>-->

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>Dylan Maus</li>
          <li><a href="mailto:xyzx@gmail.com">xyzx@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">

          <li><a href="https://github.com/dylanmaus"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">dylanmaus</span></a>
</li>
          <li>
            <a href="https://www.linkedin.com/in/dylanmaus">
              <svg class="svg-icon">
                <use
                  xlink:href="/assets/minima-social-icons.svg#linkedin"
                ></use>
              </svg>
              <span class="username">dylanmaus</span></a
            >
          </li></ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>
          Software Engineer @
          <a href="https://www.maxar.com/">Maxar</a> <br />
          MSCS @ <a href="https://www.gatech.edu/">Georgia Tech</a>
          <br />
          Machine Learning Specialization
        </p>
      </div>
    </div>
  </div>
</footer>
</body>
</html>
